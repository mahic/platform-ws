# Step 3 - Lakehouse

The two previous steps are prerequisites for building a version of the Lakehouse architecture.

Please make sure you fully understand the concept of Lakehouse architectures before moving on by reading [this short article](https://www.generativevalue.com/p/a-primer-on-the-dasta-lakehouse).

## Tasks

By now you know probably know there are many different technologies that can be used to create a Lakehouse architecture. 

* **ETL/ELT** tools such as [Airbyte](https://airbyte.com/), [Meltano](https://meltano.com/), [Singer](https://www.singer.io/), [Apache NiFi](https://nifi.apache.org/), [CloudQuery](https://www.cloudquery.io/) and [Data Load Tool](https://dlthub.com/)
* **Orchestration** tools such as [Apache Airflow](https://airflow.apache.org/), [Dagster](https://dagster.io/), [Prefect](https://www.prefect.io/), [Kestra](https://kestra.io/) and [Mage](https://www.mage.ai/)
* **Open Table formats** such as [Apache Iceberg](https://iceberg.apache.org/), [Delta Lake](https://delta.io/) and [Apache Hudi](https://hudi.apache.org/)
* *Analytical SQL query engines* such as [PrestoDB](https://prestodb.io/), [Trino](https://trino.io/), [StarRocks](https://www.starrocks.io/), [ClickHouse](https://clickhouse.com/)
* **Data transformation tools** such as [dbt](https://www.getdbt.com/), [SQLMesh](https://sqlmesh.com/)
* **Data catalog tools** such as [Datahub](https://datahubproject.io/), [Apache Atlas](https://atlas.apache.org), [OpenMetadata](https://open-metadata.org/)
* **Python libraries** such as [DuckDB](https://duckdb.org/), [Polars](https://pola.rs/)
* **Visualization tools** such as [Apache Superset](https://superset.apache.org/), [Metabase](https://www.metabase.com/), [Redash](https://redash.io/)


1. What do you thing are the challenges of implementing an on-prem data platform? 

Take note of 5 potential issues.


If you are done, move on to [task 4](./task4.md)